{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet Tutorial\n",
    "\n",
    "**This lesson is adapted from [sentdex](https://www.youtube.com/watch?v=WvoLTXIjBYU&t=1s) on YouTube. I have collated this for my own learning experience, as well as for the benefit of others who would like to learn as well. :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, make sure you have a basic understanding of how convolutional neural networks work. You can read about it [here](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53), or watch sentdex's video explanation on YouTube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import all the necessary modules that we need. Some new modules you will see here are Dropout, Conv2D and MaxPooling 2D.\n",
    "\n",
    "Dropout helps against the overfitting of our model by randomly setting the outgoing edges of hidden units (neurons that make up hidden layers) to 0 at each update of the training phase.\n",
    "\n",
    "Conv2D is a 2D Convolution Layer that creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs. \n",
    "\n",
    "MaxPooling2D is a maxpooling operation for 2D spatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the data that we have saved from the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(\"x.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "#normalise the data\n",
    "#since the maximum pixel value is 255, we will divide our x by 255 to achieve values between 0 and 1\n",
    "x = x/255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will start training our model. \n",
    "\n",
    "We can input almost anything for the first value of the convolutional 2D layer, the second value would be the window that we would like to use (3 by 3), and for the input shape, we will pass in the shape of our x, while skipping -1.\n",
    "\n",
    "Next, we can either go through with maxpooling or activation first, it doesn't matter. For activation, we will be using the widey-used [relu function](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7#:~:text=ReLU%20stands%20for%20rectified%20linear,max(0%2C%20x).&text=ReLU%20is%20the%20most%20commonly,usually%20a%20good%20first%20choice.).\n",
    "\n",
    "For this model, the dense layer is not needed, but we will add it in anyway for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#first layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape = x.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#third layer\n",
    "#first we need to flatten the dataset because conv2d pass through a 2D dataset, whereas dense accepts a 1D dataset\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#output layer with sigmoid function as activation function\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#specify the optimizer, loss function and metrics(optional)\n",
    "#loss function here is binary crossentropy because we only have 2 outputs (cat or dog)\n",
    "model.compile(loss = \"binary_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data size this time a very large (over 20000 images if I'm not wrong), passing our data 1 by 1 would prove to be too slow, and passing them all at once might cause the code to run very slowly. As a result, we will be passing them through as batches. Usually, a good batch size would be around 20, but it also depends on how big or how small your dataset is.\n",
    "\n",
    "To prevent the dataset from overfitting, we will be splittiing some of the training data intro validation data. If you would like to learn more about the importance of validation data, you can read so [here](https://machinelearningmastery.com/difference-test-validation-datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "702/702 [==============================] - 66s 93ms/step - loss: 0.6302 - accuracy: 0.6372 - val_loss: 0.5660 - val_accuracy: 0.7094\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 63s 90ms/step - loss: 0.5228 - accuracy: 0.7414 - val_loss: 0.4859 - val_accuracy: 0.7607\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 71s 101ms/step - loss: 0.4801 - accuracy: 0.7697 - val_loss: 0.4629 - val_accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 67s 96ms/step - loss: 0.4469 - accuracy: 0.7907 - val_loss: 0.4530 - val_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 63s 89ms/step - loss: 0.4129 - accuracy: 0.8091 - val_loss: 0.4484 - val_accuracy: 0.7884\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 65s 92ms/step - loss: 0.3821 - accuracy: 0.8251 - val_loss: 0.4481 - val_accuracy: 0.7896\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 66s 95ms/step - loss: 0.3494 - accuracy: 0.8461 - val_loss: 0.4329 - val_accuracy: 0.8032\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 69s 98ms/step - loss: 0.3102 - accuracy: 0.8646 - val_loss: 0.4435 - val_accuracy: 0.8036\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 66s 95ms/step - loss: 0.2735 - accuracy: 0.8825 - val_loss: 0.4593 - val_accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 66s 94ms/step - loss: 0.2357 - accuracy: 0.9025 - val_loss: 0.5188 - val_accuracy: 0.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c0244ad4a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size = 32, epochs = 10, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jodie ethelda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: dogs_cats_predict.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#save a model\n",
    "model.save('dogs_cats_predict.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a model\n",
    "new_model = tf.keras.models.load_model('dogs_cats_predict.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
