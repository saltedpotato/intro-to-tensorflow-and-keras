{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Models with TensorBoard\n",
    "\n",
    "**This lesson is adapted from [sentdex](https://www.youtube.com/watch?v=BqgTU7_cBnk) on YouTube. I have collated this for my own learning experience, as well as for the benefit of others who would like to learn as well. :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is essentially Tensorflow's visualisation toolkit. It can graph out the test and validation errors of your model to give you a visual view of how well your model is doing. You can read more about TensorBoard [here](https://www.tensorflow.org/tensorboard)\n",
    "\n",
    "First, we will import all the necessary modules, including time for the tensorboard that we will be using later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a new name with an added parameter of time. This is to ensure that we do not append to models with the same name, in case we forget to change the name of the model later on\n",
    "\n",
    "Next, we choose the directory where our tensorboard data will be placed in. For this lesson, we will be putting it in the *logs* file in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"cats-vs-dogs-cnn-64x2--{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just copy-and-pasted the codes from Lesson 3. I did try to run the saved model, but because it is already trained, I wasn't able to see the full cycle of how validation loss and training loss decreases or increases over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/546 [..............................] - ETA: 4:16 - loss: 0.6852 - accuracy: 0.5312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.439207). Check your callbacks.\n",
      "546/546 [==============================] - 63s 116ms/step - loss: 0.6594 - accuracy: 0.5988 - val_loss: 0.6149 - val_accuracy: 0.6646\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 63s 116ms/step - loss: 0.5562 - accuracy: 0.7162 - val_loss: 0.5164 - val_accuracy: 0.7512\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 61s 112ms/step - loss: 0.5070 - accuracy: 0.7526 - val_loss: 0.5038 - val_accuracy: 0.7592\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 61s 111ms/step - loss: 0.4796 - accuracy: 0.7736 - val_loss: 0.4844 - val_accuracy: 0.7682\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 60s 109ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4647 - val_accuracy: 0.7821\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 63s 116ms/step - loss: 0.4392 - accuracy: 0.7985 - val_loss: 0.4613 - val_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 61s 112ms/step - loss: 0.4183 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.7861\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 64s 117ms/step - loss: 0.4025 - accuracy: 0.8183 - val_loss: 0.4512 - val_accuracy: 0.7932\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 62s 113ms/step - loss: 0.3823 - accuracy: 0.8305 - val_loss: 0.4433 - val_accuracy: 0.7978\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 63s 116ms/step - loss: 0.3681 - accuracy: 0.8385 - val_loss: 0.4528 - val_accuracy: 0.7909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x194a79adcf8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pickle.load(open(\"x.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "#normalise the data\n",
    "#since the maximum pixel value is 255, we will divide our x by 255 to achieve values between 0 and 1\n",
    "x = x/255.0\n",
    "y = np.array(y)\n",
    "\n",
    "#using the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#first layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape = x.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#third layer\n",
    "#first we need to flatten the dataset because conv2d pass through a 2D dataset, whereas dense accepts a 1D dataset\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "#output layer with sigmoid function as activation function\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#specify the optimizer, loss function and metrics(optional)\n",
    "#loss function here is binary crossentropy because we only have 2 outputs (cat or dog)\n",
    "model.compile(loss = \"binary_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(x, y, batch_size = 32, epochs = 10, validation_split = 0.3, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will access tensorboard by simply entering the directory where your logs file is at, and run the following command on your command prompt:\n",
    "\n",
    "*tensorboard --logdir=logs/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
